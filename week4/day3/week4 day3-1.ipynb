{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Import data and libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "baseDf = pd.read_csv('../../data/helathcareforall.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      CONTROLN STATE GENDER      HV1  IC1    IC4  HVP1    IC5  POBC1  POBC2  \\\n0        44060    FL      M   AAA896  392  520.0     7  21975      6     16   \n1        96093    IL      M   537.00  365  473.0     0  19387      1     89   \n2        43333    FL      F   725.00  301  436.0     3  18837     11     17   \n3        21885    NC      M  AAA1095  401  413.0     7  14014      1     74   \n4       190108    FL      F   995.00  252  348.0     0  17991      5      6   \n...        ...   ...    ...      ...  ...    ...   ...    ...    ...    ...   \n1002    114721    OK    NaN     1040  472  656.0     0  26962      2     56   \n1003    149152    CA      M     4507  842  962.0    95  54642     17     50   \n1004       959    IA      F      586  349  465.0     1  15304      1     77   \n1005    179563    WA   male      842  420  494.0     2  12894     41     24   \n1006     41243    FL      F      556  246  330.0     0  10272      2     56   \n\n         IC2  IC3    AVGGIFT  TCODE   DOB DOMAIN  TARGET_D  \n0      430.0  466  28.000000      1  1901     C2     100.0  \n1      415.0  410   5.666667      0     0     T2       7.0  \n2      340.0  361   4.111111      0  2501     C2       5.0  \n3      407.0  399  27.277778      0  2208     T2      38.0  \n4      280.0  316   6.000000     28     0     C2       5.0  \n...      ...  ...        ...    ...   ...    ...       ...  \n1002   609.0  579  11.666667      0     0     C2      15.0  \n1003  1004.0  893  20.000000      1  4401     S1      20.0  \n1004   413.0  404   7.300000      0  4404     C2      10.0  \n1005   419.0  476  16.400000      1  5001     S2      23.0  \n1006   277.0  292   9.818182      2  2201     S2      12.0  \n\n[1007 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CONTROLN</th>\n      <th>STATE</th>\n      <th>GENDER</th>\n      <th>HV1</th>\n      <th>IC1</th>\n      <th>IC4</th>\n      <th>HVP1</th>\n      <th>IC5</th>\n      <th>POBC1</th>\n      <th>POBC2</th>\n      <th>IC2</th>\n      <th>IC3</th>\n      <th>AVGGIFT</th>\n      <th>TCODE</th>\n      <th>DOB</th>\n      <th>DOMAIN</th>\n      <th>TARGET_D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44060</td>\n      <td>FL</td>\n      <td>M</td>\n      <td>AAA896</td>\n      <td>392</td>\n      <td>520.0</td>\n      <td>7</td>\n      <td>21975</td>\n      <td>6</td>\n      <td>16</td>\n      <td>430.0</td>\n      <td>466</td>\n      <td>28.000000</td>\n      <td>1</td>\n      <td>1901</td>\n      <td>C2</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96093</td>\n      <td>IL</td>\n      <td>M</td>\n      <td>537.00</td>\n      <td>365</td>\n      <td>473.0</td>\n      <td>0</td>\n      <td>19387</td>\n      <td>1</td>\n      <td>89</td>\n      <td>415.0</td>\n      <td>410</td>\n      <td>5.666667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>T2</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>43333</td>\n      <td>FL</td>\n      <td>F</td>\n      <td>725.00</td>\n      <td>301</td>\n      <td>436.0</td>\n      <td>3</td>\n      <td>18837</td>\n      <td>11</td>\n      <td>17</td>\n      <td>340.0</td>\n      <td>361</td>\n      <td>4.111111</td>\n      <td>0</td>\n      <td>2501</td>\n      <td>C2</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21885</td>\n      <td>NC</td>\n      <td>M</td>\n      <td>AAA1095</td>\n      <td>401</td>\n      <td>413.0</td>\n      <td>7</td>\n      <td>14014</td>\n      <td>1</td>\n      <td>74</td>\n      <td>407.0</td>\n      <td>399</td>\n      <td>27.277778</td>\n      <td>0</td>\n      <td>2208</td>\n      <td>T2</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>190108</td>\n      <td>FL</td>\n      <td>F</td>\n      <td>995.00</td>\n      <td>252</td>\n      <td>348.0</td>\n      <td>0</td>\n      <td>17991</td>\n      <td>5</td>\n      <td>6</td>\n      <td>280.0</td>\n      <td>316</td>\n      <td>6.000000</td>\n      <td>28</td>\n      <td>0</td>\n      <td>C2</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1002</th>\n      <td>114721</td>\n      <td>OK</td>\n      <td>NaN</td>\n      <td>1040</td>\n      <td>472</td>\n      <td>656.0</td>\n      <td>0</td>\n      <td>26962</td>\n      <td>2</td>\n      <td>56</td>\n      <td>609.0</td>\n      <td>579</td>\n      <td>11.666667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>C2</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>149152</td>\n      <td>CA</td>\n      <td>M</td>\n      <td>4507</td>\n      <td>842</td>\n      <td>962.0</td>\n      <td>95</td>\n      <td>54642</td>\n      <td>17</td>\n      <td>50</td>\n      <td>1004.0</td>\n      <td>893</td>\n      <td>20.000000</td>\n      <td>1</td>\n      <td>4401</td>\n      <td>S1</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>959</td>\n      <td>IA</td>\n      <td>F</td>\n      <td>586</td>\n      <td>349</td>\n      <td>465.0</td>\n      <td>1</td>\n      <td>15304</td>\n      <td>1</td>\n      <td>77</td>\n      <td>413.0</td>\n      <td>404</td>\n      <td>7.300000</td>\n      <td>0</td>\n      <td>4404</td>\n      <td>C2</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>179563</td>\n      <td>WA</td>\n      <td>male</td>\n      <td>842</td>\n      <td>420</td>\n      <td>494.0</td>\n      <td>2</td>\n      <td>12894</td>\n      <td>41</td>\n      <td>24</td>\n      <td>419.0</td>\n      <td>476</td>\n      <td>16.400000</td>\n      <td>1</td>\n      <td>5001</td>\n      <td>S2</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>41243</td>\n      <td>FL</td>\n      <td>F</td>\n      <td>556</td>\n      <td>246</td>\n      <td>330.0</td>\n      <td>0</td>\n      <td>10272</td>\n      <td>2</td>\n      <td>56</td>\n      <td>277.0</td>\n      <td>292</td>\n      <td>9.818182</td>\n      <td>2</td>\n      <td>2201</td>\n      <td>S2</td>\n      <td>12.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1007 rows Ã— 17 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "split numerical from categorical"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "numerical = baseDf.select_dtypes(include=np.number)\n",
    "categorical = baseDf.select_dtypes(include=object)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Linear Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train-test split."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "     CONTROLN  IC1    IC4  HVP1  POBC1  POBC2    IC2  IC3    AVGGIFT  TCODE  \\\n591     90031  417  540.0     2     11     71  472.0  494   3.722222      2   \n178     15668  383  433.0     0      0     84  400.0  398   9.333333      0   \n841    102351  208  356.0     0      0     59  271.0  264  13.333333      0   \n243     54142  210  310.0     0      0     55  254.0  272  13.000000      2   \n944     35325  277  387.0     0      8     21  350.0  329  12.142857      0   \n..        ...  ...    ...   ...    ...    ...    ...  ...        ...    ...   \n988     66223  319  398.0     3      2     83  345.0  357   9.571429      0   \n322     10973  563  660.0    75      8     59  579.0  655  10.894737      1   \n382     16099  282  335.0     1      0     81  291.0  327   5.500000      0   \n365    152527  289  402.0    37      9     50  377.0  339  23.000000     28   \n510     44853  246  323.0     0      3     13  323.0  275  10.642857      1   \n\n      DOB  \n591  1601  \n178  4101  \n841  3301  \n243  4601  \n944  1801  \n..    ...  \n988  5801  \n322  2305  \n382  2701  \n365  4501  \n510  2912  \n\n[704 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CONTROLN</th>\n      <th>IC1</th>\n      <th>IC4</th>\n      <th>HVP1</th>\n      <th>POBC1</th>\n      <th>POBC2</th>\n      <th>IC2</th>\n      <th>IC3</th>\n      <th>AVGGIFT</th>\n      <th>TCODE</th>\n      <th>DOB</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>591</th>\n      <td>90031</td>\n      <td>417</td>\n      <td>540.0</td>\n      <td>2</td>\n      <td>11</td>\n      <td>71</td>\n      <td>472.0</td>\n      <td>494</td>\n      <td>3.722222</td>\n      <td>2</td>\n      <td>1601</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>15668</td>\n      <td>383</td>\n      <td>433.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>84</td>\n      <td>400.0</td>\n      <td>398</td>\n      <td>9.333333</td>\n      <td>0</td>\n      <td>4101</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>102351</td>\n      <td>208</td>\n      <td>356.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>59</td>\n      <td>271.0</td>\n      <td>264</td>\n      <td>13.333333</td>\n      <td>0</td>\n      <td>3301</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>54142</td>\n      <td>210</td>\n      <td>310.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>55</td>\n      <td>254.0</td>\n      <td>272</td>\n      <td>13.000000</td>\n      <td>2</td>\n      <td>4601</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>35325</td>\n      <td>277</td>\n      <td>387.0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>21</td>\n      <td>350.0</td>\n      <td>329</td>\n      <td>12.142857</td>\n      <td>0</td>\n      <td>1801</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>66223</td>\n      <td>319</td>\n      <td>398.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>83</td>\n      <td>345.0</td>\n      <td>357</td>\n      <td>9.571429</td>\n      <td>0</td>\n      <td>5801</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>10973</td>\n      <td>563</td>\n      <td>660.0</td>\n      <td>75</td>\n      <td>8</td>\n      <td>59</td>\n      <td>579.0</td>\n      <td>655</td>\n      <td>10.894737</td>\n      <td>1</td>\n      <td>2305</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>16099</td>\n      <td>282</td>\n      <td>335.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>81</td>\n      <td>291.0</td>\n      <td>327</td>\n      <td>5.500000</td>\n      <td>0</td>\n      <td>2701</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>152527</td>\n      <td>289</td>\n      <td>402.0</td>\n      <td>37</td>\n      <td>9</td>\n      <td>50</td>\n      <td>377.0</td>\n      <td>339</td>\n      <td>23.000000</td>\n      <td>28</td>\n      <td>4501</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>44853</td>\n      <td>246</td>\n      <td>323.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>13</td>\n      <td>323.0</td>\n      <td>275</td>\n      <td>10.642857</td>\n      <td>1</td>\n      <td>2912</td>\n    </tr>\n  </tbody>\n</table>\n<p>704 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = numerical.drop('TARGET_D', axis=1)\n",
    "y = numerical.TARGET_D\n",
    "X = X._get_numeric_data()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=123)\n",
    "# X_train.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardize the data (after the data split)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.42736901, -0.9024371 , -1.04761825, ..., -0.90580767,\n        -0.18165298, -0.49718631],\n       [-1.47782996, -0.59790459, -0.57751928, ...,  0.3648657 ,\n        -0.18165298,  0.30945377],\n       [ 0.58367308, -0.71971759, -0.8399001 , ...,  0.38180288,\n        -0.18165298, -1.20940205],\n       ...,\n       [-1.15946276,  0.1606582 ,  0.30801598, ..., -0.57091345,\n        -0.18165298,  0.87884677],\n       [-0.98982459, -0.81384582, -1.11321345, ...,  1.0169471 ,\n        -0.18165298, -1.20940205],\n       [ 1.48149738, -1.10730442, -1.23347133, ..., -0.81589765,\n        -0.17739047, -0.96788452]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_scaler = StandardScaler().fit(X_train)  ##. finding the parameters ( mean, variance from the training set )\n",
    "X_train_scaled = std_scaler.transform(X_train)\n",
    "X_train.shape\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "X_test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply linear regression."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m=\u001B[39mLinearRegression()    \u001B[38;5;66;03m# model\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_base.py:684\u001B[0m, in \u001B[0;36mLinearRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    680\u001B[0m n_jobs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs\n\u001B[0;32m    682\u001B[0m accept_sparse \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositive \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoo\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m--> 684\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    685\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[0;32m    686\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    688\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(\n\u001B[0;32m    689\u001B[0m     sample_weight, X, dtype\u001B[38;5;241m=\u001B[39mX\u001B[38;5;241m.\u001B[39mdtype, only_non_negative\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    690\u001B[0m )\n\u001B[0;32m    692\u001B[0m X, y, X_offset, y_offset, X_scale \u001B[38;5;241m=\u001B[39m _preprocess_data(\n\u001B[0;32m    693\u001B[0m     X,\n\u001B[0;32m    694\u001B[0m     y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    698\u001B[0m     sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m    699\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    594\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 596\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1072\u001B[0m     )\n\u001B[1;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1092\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:899\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    893\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    894\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    895\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    896\u001B[0m         )\n\u001B[0;32m    898\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 899\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    901\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    902\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    903\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    904\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    907\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    124\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    125\u001B[0m             \u001B[38;5;129;01mnot\u001B[39;00m allow_nan\n\u001B[0;32m    126\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m estimator_name\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    130\u001B[0m             \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    131\u001B[0m             \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    132\u001B[0m             msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    133\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    134\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    144\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    145\u001B[0m             )\n\u001B[1;32m--> 146\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n\u001B[0;32m    148\u001B[0m \u001B[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobject\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_nan:\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "   # model train\n",
    "\n",
    "# X_train_const_scaled = sm.add_constant(X_train_scaled)  # adding a constant\n",
    "#\n",
    "# # model = sm.OLS(y_train, X_train_const_scaled).fit()\n",
    "# predictions_train = model.predict(X_train_const_scaled)\n",
    "# predictions_train\n",
    "# # X_test_const_scaled = sm.add_constant(X_test_scaled)  # adding a constant test data\n",
    "# # predictions_test = model.predict(X_test_const_scaled)\n",
    "# # print_model = model.summary()\n",
    "# model = LinearRegression()  # model\n",
    "# # model.fit(X_train_scaled, y_train)  # model train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model Interpretation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}